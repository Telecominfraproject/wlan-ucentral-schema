# Template Testing Guide

This guide explains how to test ucode templates during refactoring to ensure they produce correct UCI output while following the new design patterns.

## Test Infrastructure

### Directory Structure
```
tests/
â”œâ”€â”€ test-runner.uc                    # Master test runner (discovers & runs all suites)
â”œâ”€â”€ helpers/
â”‚   â””â”€â”€ mock-renderer.uc             # Shared mock environment
â””â”€â”€ unit/
    â””â”€â”€ services/
        â”œâ”€â”€ log/
        â”‚   â”œâ”€â”€ input/
        â”‚   â”‚   â”œâ”€â”€ log-basic.json
        â”‚   â”‚   â””â”€â”€ log-with-hostname.json
        â”‚   â”œâ”€â”€ output/
        â”‚   â”‚   â”œâ”€â”€ log-basic.uci
        â”‚   â”‚   â””â”€â”€ log-with-hostname.uci
        â”‚   â””â”€â”€ test-log.uc             # Log service test suite
        â””â”€â”€ lldp/
            â”œâ”€â”€ input/
            â”‚   â”œâ”€â”€ lldp-basic.json
            â”‚   â”œâ”€â”€ lldp-no-service.json
            â”‚   â””â”€â”€ lldp-multiple-interfaces.json
            â”œâ”€â”€ output/
            â”‚   â”œâ”€â”€ lldp-basic.uci
            â”‚   â”œâ”€â”€ lldp-no-service.uci
            â”‚   â””â”€â”€ lldp-multiple-interfaces.uci
            â””â”€â”€ test-lldp.uc           # LLDP service test suite
```

Each template gets its own self-contained test directory with:
- **`input/`** - JSON test fixture files  
- **`output/`** - Expected UCI output files
- **`test-{service}.uc`** - Test suite script for that specific template

### Mock Environment

The `mock-renderer.uc` provides:
- **System mocks**: `cursor`, `conn`, `fs`, `capab`, `restrict`, `default_config`
- **UCI helpers**: All `uci_*` functions with proper null handling
- **Service discovery**: Mock `services` object with common methods
- **Utility objects**: Mock `ethernet`, `files`, `shell` objects

Key mocked components:
- UCI cursor returns predictable test data
- Filesystem operations return mock file contents
- ubus calls return empty responses
- Service discovery returns common service lists

## Writing Tests

### 1. Create Template Test Directory

For a new service template (e.g., `ssh.uc`), create the directory structure:

```bash
mkdir -p tests/unit/services/ssh/{input,output}
```

### 2. Create Test Fixtures

Create JSON files in `input/` with template input data:

**`tests/unit/services/ssh/input/ssh-basic.json`**
```json
{
  "template_vars": {
    "ssh": {
      "port": "2222",
      "password_authentication": true,
      "authorized_keys": ["ssh-rsa AAAA..."]
    }
  },
  "state": {
    "interfaces": [
      {
        "role": "upstream",
        "services": ["ssh"]
      }
    ]
  }
}
```

### 3. Create Expected Output

Create UCI files in `output/` with the exact expected output:

**`tests/unit/services/ssh/output/ssh-basic.uci`**
```uci
# generated by ssh.uc

### generate SSH configuration
set dropbear.@dropbear[-1].enable='1'
set dropbear.@dropbear[-1].Port='2222'
set dropbear.@dropbear[-1].PasswordAuth='1'
add firewall rule
set firewall.@rule[-1].name='Allow-ssh-mock_interface'
set firewall.@rule[-1].src='mock_interface'
set firewall.@rule[-1].dest_port='2222'
set firewall.@rule[-1].proto='tcp'
set firewall.@rule[-1].target='ACCEPT'
```

### 4. Create Test Suite Script

Create a test suite script that runs all test cases for the template:

**`tests/unit/services/ssh/test-ssh.uc`**
```javascript
#!/usr/bin/env ucode

// SSH service template unit tests

"use strict";

import * as fs from 'fs';
import { create_test_context } from '../../../helpers/mock-renderer.uc';

let test_results = {
    passed: 0,
    failed: 0,
    errors: []
};

function run_test(test_name, input_file, expected_file) {
    printf("Running test: %s\n", test_name);
    
    try {
        // Load test data
        let test_data = json(fs.readfile(input_file));
        let expected_output = fs.readfile(expected_file);
        
        // Handle empty expected files
        if (expected_output === null || expected_output === false) {
            expected_output = "";
        }
        
        // Create test context
        let context = create_test_context(test_data);
        
        // Add template vars to context
        for (let key, value in test_data.template_vars || {}) {
            context[key] = value;
        }
        
        // Render template
        let output = render("../../../../renderer/templates/services/ssh.uc", context);
        
        // Normalize whitespace for comparison
        output = trim(replace(output, /\n\s*\n/g, '\n'));
        expected_output = trim(replace(expected_output, /\n\s*\n/g, '\n'));
        
        // Compare output
        if (output == expected_output) {
            printf("âœ“ PASS: %s\n", test_name);
            test_results.passed++;
        } else {
            printf("âœ— FAIL: %s\n", test_name);
            printf("Expected:\n%s\n", expected_output);
            printf("Got:\n%s\n", output);
            test_results.failed++;
            push(test_results.errors, { test: test_name, expected: expected_output, actual: output });
        }
    } catch (e) {
        printf("âœ— ERROR: %s - %s\n", test_name, e);
        test_results.failed++;
        push(test_results.errors, { test: test_name, error: e.message || e });
    }
    
    printf("\n");
}

function main() {
    printf("=== SSH Service Template Tests ===\n\n");
    
    // Run all test cases
    run_test("ssh-basic", "input/ssh-basic.json", "output/ssh-basic.uci");
    run_test("ssh-no-service", "input/ssh-no-service.json", "output/ssh-no-service.uci");
    
    // Print summary
    printf("=== Test Results ===\n");
    printf("Passed: %d\n", test_results.passed);
    printf("Failed: %d\n", test_results.failed);
    
    if (test_results.failed > 0) {
        printf("\nFailures:\n");
        for (let error in test_results.errors) {
            printf("- %s\n", error.test);
            if (error.error) {
                printf("  Error: %s\n", error.error);
            }
        }
        exit(1);
    }
    
    printf("All SSH service tests passed!\n");
}

main();
```

### 5. Test Discovery (Automatic)

The master test runner automatically discovers all test suites by finding `test-*.uc` files in the directory structure. No manual registration needed!

## Test Categories

### Unit Tests (Individual Templates)
- **Basic functionality**: Template with typical configuration
- **Empty config**: Template with no/empty configuration data
- **Edge cases**: Null values, missing fields, extreme values
- **Error handling**: Invalid configurations, missing dependencies

### Integration Tests (Template Combinations)
- **Service discovery**: Templates that use `services.lookup_*`
- **Context passing**: Templates that include sub-templates
- **State dependencies**: Templates that depend on global state

### Regression Tests
- **Old vs new**: Compare refactored template output with original
- **Pattern compliance**: Validate new organizational patterns are used
- **UCI helper usage**: Ensure `uci_*` functions replace manual formatting

## Common Test Patterns

### Testing Empty Configuration
```javascript
function test_service_no_config() {
    let test_data = {
        template_vars: {},  // No service config
        state: {}
    };
    let expected = "";  // Should return empty
    
    run_test("service-no-config", "../renderer/templates/services/service.uc", test_data, expected);
}
```

### Testing Hostname Fallback
```javascript
function test_service_hostname_fallback() {
    let test_data = {
        template_vars: { service: { host: "example.com" } },
        state: { unit: {} }  // No hostname in unit
    };
    let expected = "set config.hostname='mock-hostname'";  // Uses mock fallback
    
    run_test("service-hostname", "../renderer/templates/services/service.uc", test_data, expected);
}
```

### Testing Service Discovery
```javascript
function test_service_with_interfaces() {
    let test_data = {
        template_vars: { service: { enabled: true } },
        context: {
            services: {
                lookup_interfaces: function(name) {
                    return [{ role: "upstream" }];  // Mock interface
                }
            }
        }
    };
    // Expected output includes interface-specific config
}
```

## Running Tests

### Execute All Tests
```bash
cd tests
ucode test-runner.uc
```

### Execute Individual Template Tests
```bash
cd tests/unit/services/log
ucode test-log.uc
```

### Expected Output

**Master Test Runner:**
```
=== Template Test Suite Runner ===

Found 2 test suites:
  - unit/services/lldp/test-lldp.uc
  - unit/services/log/test-log.uc

Running test suite: unit/services/lldp/test-lldp.uc
==================================================
=== LLDP Service Template Tests ===

Running test: lldp-basic
âœ“ PASS: lldp-basic

Running test: lldp-no-service
âœ“ PASS: lldp-no-service

=== Test Results ===
Passed: 2
Failed: 0
All LLDP service tests passed!
âœ“ Test suite PASSED

Running test suite: unit/services/log/test-log.uc
==================================================
=== Log Service Template Tests ===

Running test: log-basic
âœ“ PASS: log-basic

=== Test Results ===
Passed: 1
Failed: 0
All log service tests passed!
âœ“ Test suite PASSED

==================================================
=== FINAL RESULTS ===
Test suites run: 2
Passed: 2
Failed: 0
All test suites passed! ðŸŽ‰
```

## Debugging Test Failures

### Failed Output Comparison
When a test fails, the runner shows:
```
âœ— FAIL: service-basic
Expected:
set config.param='expected'

Got:
set config.param='actual'
```

### Common Issues
1. **Whitespace differences**: Trailing spaces, inconsistent line endings
2. **Quote formatting**: Manual vs `uci_*` helper quoting differences  
3. **Empty output**: Template returning empty when config missing
4. **Mock data**: Template expecting different mock responses

### Debugging Steps
1. Check template path is correct (`../../../../renderer/templates/services/...`)
2. Verify fixture data matches template expectations
3. Ensure expected output matches new UCI helper formatting
4. Add debug prints to template to trace execution
5. Run individual test suite for easier debugging: `cd tests/unit/services/service && ucode test-service.uc`

## Test Validation Checklist

When adding tests for a refactored template:

- [ ] **Basic functionality**: Template works with typical config
- [ ] **Empty config**: Template handles missing/empty configuration gracefully
- [ ] **Edge cases**: Template handles null values, missing fields appropriately
- [ ] **Helper usage**: Template uses `uci_*` helpers instead of manual formatting
- [ ] **Organization**: Template follows new pattern (constants, helpers, generators)
- [ ] **Traceability**: Template includes proper file header and function comments
- [ ] **Guard clauses**: Template has early validation and returns
- [ ] **Output format**: Generated UCI matches expected formatting exactly

## Mock Customization

### Adding Custom Mocks
To add service-specific mocks, extend the test context:

```javascript
let custom_context = {
    my_service: {
        custom_method: function() { return "mock_result"; }
    }
};

run_test("custom-test", template_path, test_data, expected, custom_context);
```

### Overriding Default Mocks
```javascript
let test_data = {
    template_vars: { service: {} },
    context: {
        services: {
            lookup_interfaces: function(name) {
                return []; // Override to return no interfaces
            }
        }
    }
};
```

## Benefits of Hierarchical Structure

1. **Self-contained**: Each template has its own directory with all test data and scripts
2. **Scalable**: Easy to add new service templates - just create new directory under `unit/services/`
3. **Organized**: Clear separation between input fixtures and expected output
4. **Discoverable**: Master test runner automatically finds and runs all test suites
5. **Isolated**: Each test suite runs independently in its own directory context
6. **Maintainable**: Template-specific tests are easy to locate and modify

## Adding Tests for New Templates

To add tests for a new service template:

1. **Create directory**: `mkdir -p tests/unit/services/{service_name}/{input,output}`
2. **Add test fixtures**: Create JSON files in `input/` directory
3. **Add expected output**: Create UCI files in `output/` directory  
4. **Create test suite**: Copy and adapt `test-{service}.uc` from existing template
5. **Run tests**: Master test runner automatically discovers and runs new tests

No manual registration or configuration needed - the test infrastructure is fully discoverable and self-organizing.

This testing infrastructure ensures refactored templates maintain correctness while adopting the new organizational patterns defined in TEMPLATES.md.